# Ollama Chat Interface - Environment Variables Template
# ======================================================

# Ollama Configuration (Optional - defaults are provided in config.yaml)
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=deepseek-r1:latest

# Note: This project uses local Ollama installation.
# No API keys are required.

# Setup Instructions:
# 1. Ensure Ollama is installed and running: ollama serve
# 2. Pull the required model: ollama pull deepseek-r1:latest
# 3. (Optional) Copy this file: cp .env.example .env
# 4. (Optional) Customize settings in .env or config.yaml

# Verify Ollama is running:
# curl http://localhost:11434/api/version
